## Table of Contents

- [딥러닝과 머신러닝의 차이가 무엇인가요?](#1)
- [Cost Function과 Activation Function은 무엇인가요?](#2)
- [Tensorflow, PyTorch 특징과 차이가 뭘까요?](#3)
- [Data Normalization은 무엇이고 왜 필요한가요?](#4)
- [알고있는 Activation Function에 대해 알려주세요. (Sigmoid, ReLU, LeakyReLU, Tanh 등)](#5)
- [오버피팅일 경우 어떻게 대처해야 할까요?](#6)
- [하이퍼 파라미터는 무엇인가요?](#7)
- [Weight Initialization 방법에 대해 말해주세요. 그리고 무엇을 많이 사용하나요?](#8)
- [볼츠만 머신은 무엇인가요?](#9)
- [TF, PyTorch 등을 사용할 때 디버깅 노하우는?](#10)
- [Neural-Net의 가장 큰 단점은 무엇인가? 이를 위해 나온 One-Shot Learning은 무엇인가?](#11)
- [요즘 Sigmoid 보다 ReLU를 많이 쓰는데 그 이유는?](#12)
- [Non-Linearity라는 말의 의미와 그 필요성은?](#13)
- [ReLU로 어떻게 곡선 함수를 근사하나?](#14)
- [ReLU의 문제점은?](#15)
- [Bias는 왜 있는걸까?](#16)

---

## #1

### 딥러닝과 머신러닝의 차이가 무엇인가요?



답변  ~~

---

## #2

### Cost Function과 Activation Function은 무엇인가요?

답변 ~~

---

## #3

### Tensorflow, PyTorch 특징과 차이가 뭘까요?

답변 ~~

---

## #4

### Data Normalization은 무엇이고 왜 필요한가요?

답변 ~~

---

## #5

### 알고있는 Activation Function에 대해 알려주세요. (Sigmoid, ReLU, LeakyReLU, Tanh 등)



답변  ~~

---

## #6

### 오버피팅일 경우 어떻게 대처해야 할까요?

답변 ~~

---

## #7

### 하이퍼 파라미터는 무엇인가요?

답변 ~~

---

## #8

### Weight Initialization 방법에 대해 말해주세요. 그리고 무엇을 많이 사용하나요?

답변 ~~

---

## #9

### 볼츠만 머신은 무엇인가요?

답변 ~~

---

## #10

### TF, PyTorch 등을 사용할 때 디버깅 노하우는?

답변 ~~

---

## #11

### Neural-Net의 가장 큰 단점은 무엇인가? 이를 위해 나온 One-Shot Learning은 무엇인가?

답변 ~~

---
## #12

### 요즘 Sigmoid 보다 ReLU를 많이 쓰는데 그 이유는?

답변 ~~

---

## #13

### Non-Linearity라는 말의 의미와 그 필요성은?

답변 ~~

---

## #14

### ReLU로 어떻게 곡선 함수를 근사하나?

답변 ~~

---

## #15

### ReLU의 문제점은?

답변 ~~

---

## #116

### Bias는 왜 있는걸까?

답변 ~~

---

