# 면접1 답변

1. **고유값(eigen value)와 고유벡터(eigen vector)이 무엇이고 왜 중요한지 설명해주세요.**

   1. 행렬 A를 이용해 어떤 벡터 v에 사칙연산을 가했을 때, 그 결과가 벡터 v의 상수배가 되도록 하는 0이 아닌 벡터 v를 eigen vector라 하고 그 상수배(λ)의 값를 eigen value라 합니다.

      $$
      A\bold{v}=\lambda \bold{v}
      $$

      이 때의 행렬 A는 n\*n 정방행렬(square matrix)입니다. 기하학적인 의미를 살펴보면, 벡터 x에 n차 정방행렬 A를 곱한 결과와 상수인 λ(고유값)를 곱한 결과가 같음을 의미합니다.
      따라서 이러한 고유 벡터는 임의의 벡터를 어느 방향으로 얼만큼 변화시키는지, 변환 과정에서 변화 없이 유지되는 부분은 어느 부분인지 등의 정보를 담고 있어 PCA, Eigen Decomposition과 같은 응용에 활용됩니다. 또한 연산 과정에서 결과 값을 예측할 수 있기 때문에 Eigen value와 Eigen vector는 연산 효율성의 측면에서 이점을 가집니다.

2. **샘플링(Sampling)과 리샘플링(Resampling)이 무엇이고 리샘플링의 장점을 말씀해주세요.**

   1. 정의
      **샘플링은 어떤 자료**(모집단)**에서 일부 값**(표본)**을 추출하는 것이고, 리샘플링은 샘플링된 데이터 내에서 다시 샘플링하는 것이다.** 모집단을 전부 조사하는 것은 불가능하기 때문에 샘플링을 하는 것이며, 모집단을 대표할 수 있는 표본을 추출하여 추론을 수행한다.
   2. 장점
      **샘플링을 통해 데이터를 정리하여 추출하면 딥러닝/머신러닝에 최적화된 입력값을 만들 수 있다.** **전체 데이터의 분포 형태를 알 수 없을 때, 리샘플링을 통해 샘플링된 데이터의 부분 집합을 반복적으로 뽑으며 추가적인 정보나 데이터의 특성, 패턴을 모델에 학습시킬 수 있다.**
      리샘플링은 표본을 반복 추출하면서 원래 데이터셋을 복원하므로 모집단의 분포 형태를 알 수 없을 때 유용하며, 통계량의 변동성을 확인할 수 있다. 따라서 모집단의 분포를 모르더라도 표본만으로 추론이 가능하다.
   3. 단점
      샘플링을 통해 추출된 표본은 모집단을 닮은 하나의 집단이지만, 모집단 그 자체가 아니므로, 표본에는 모집단의 패턴에서 놓친 부분이나 noise가 존재한다.
   4. 예시) 리샘플링 기법의 예시: k-fold cross validation, bootstrapping 등

      1. **k-fold cross validation**: 하이퍼파라미터를 튜닝하거나 적은 데이터로 학습하고 성능평가를 할 때 사용한다.
         1. 하이퍼파라미터 튜닝을 할 때 - 데이터셋이 있을 때 train set과 test set으로 나누는데, train set을 다시 k개로 쪼갤 수 있다. k개로 쪼갠 train set 중 하나를 골라 그 고른 set을 제외한 나머지 k-1개의 데이터셋에 대해 학습을 진행한 후 골랐던 set을 이용해 성능을 평가한다. 이 과정을 여러 번 반복하면서 매 학습시마다 하이퍼파라미터를 달리 해 k번 진행하는 것이다. 그러면 k개의 성능이 나오고, 가장 높은 성능을 보였던 하이퍼파라미터를 골라 전체 train set에 대한 학습에 사용한다.
         2. 적은 데이터로 학습하고 성능평가를 할 때 - 주어진 데이터셋을 k개로 나누고 하나를 고른다. 나머지 k-1개에 대해 학습을 하고 골라둔 데이터셋을 이용해 성능을 평가한다. 골랐던 데이터셋을 다시 고르지는 않으며, 이 과정을 k번 반복한다. 그러면 k개의 성능이 나오는데, 이를 평균내에 모델의 성능으로 사용한다.
      2. **bootstrapping**: 원래 데이터셋으로부터 반복적으로 샘플링을 하여 통계적 추정을 하는 기법이다. 이 방법은 특히 표본 크기가 작거나, 원래 모집단에 대한 가정이 어려울 때 유용하다.
         부트스트래핑의 기본적인 과정: 1. Resampling: 원본 데이터셋에서 랜덤하게 샘플을 선택한다. 이때 선택은 한 번 선택된 데이터는 다시 원본 데이터 세트로 돌아가고, 다시 추출될 수 있는 복원 추출 방식을 사용한다. 2. 통계량 계산: resampling된 각 셋에 대해 원하는 통계량(예: 평균, 중앙값, 분산 등)을 계산한다. 3. 분포 추정: 여러 번의 resampling과 통계량 계산을 통해 얻은 결과들로부터 통계량의 분포를 추정한다. 4. 신뢰 구간과 가설 검정: 추정된 분포를 바탕으로 신뢰 구간을 계산하거나 가설 검정을 수행할 수 있다.

      부트스트래핑은 많은 수의 재표본을 필요로 하며, 컴퓨터를 이용한 계산이 필수적이다. 이 방법은 모집단에 대한 가정이 불확실하거나, 전통적인 통계적 방법을 적용하기 어려운 경우 유용하게 사용된다. 그러나 부트스트래핑은 모든 상황에서 적절한 것은 아니며, 특히 샘플이 매우 작거나, 데이터가 매우 편향되어 있을 경우에는 부적절할 수 있다.

3. **확률 모형과 확률 변수는 무엇인가요?**
   1. **확률 변수**는 확률로 표현하기 위한 event를 정의하는 것으로, 확률변수 X를 3 이하의 자연수라고 정의하면 X={1,2,3}이 된다. 예를 들어 어떤 sample space S가 한 교실에 있는 학생들이라 할 때, 그 중에서 안경을 쓴 학생을 뽑는 것을 확률 변수 X로 정의하고, P{X} = 0.3이라면 X라는 사건이 일어날 확률은 0.3인 것이다.
      이렇게 확률이 정의된 space에서 이러한 확률변수를 0과 1 사이의 확률로 mapping하는 함수를 **확률 함수**라고 한다.
      이 때 확률이라는 것은 불확실성을 내포하고 있는데, 이러한 불확실성을 계량화하기 위해 확률함수를 수학적으로 만든 모형이 **확률 모형**이다. 확률 모형은 확률 변수를 정의함으로써 event가 발생할 확률을 구하고 전체 데이터와 확률 사이의 관계를 정의한다. 이를 이용해 갖고 있는 데이터의 분포를 수학적으로 정의할 수 있으며, 적절한 모수(확률 함수의 계수)를 사용한 확률 함수를 통해 만든 확률 모형은 기존의 데이터와 유사한 데이터 분포를 갖는 새로운 데이터를 만들 수 있게 해준다.

---

1.  **알고 있는 metric에 대해 설명해주세요. (ex. RMSE, MAE, recall, precision ...)**

    1. **RMSE**: Root Mean Square Error, 각 원소의 평균까지의 편차 제곱의 평균 (분산과 유사). RMSE 값을 구하기 위해서 실제값과 예측값의 차를 제곱한 값의 평균을 구하고 루트를 씌운다. 제곱을 하는 이유는 오차값을 양수로 하기 위함이다. 하지만 제곱 계산을 통해 평균값이 커지면 데이터셋의 크기가 방대한 경우 연산 속도가 느려질 수 있기 때문에 이러한 단점을 보완하고자 오차제곱합의 평균에 루트를 씌웁니다. RMSE 값이 작게 나올수록 정밀도(precision)가 높다고 볼 수 있으며, 실제값과 예측값의 차 제곱 후 루트, 작을수록 정밀도 높다고 해석할 수 있다.
       머신러닝에서 주로 쓰는 metric으로, 분산은 실제 평균과의 차이의 제곱을 사용하기 때문에 큰 오류의 영향이 작은 오류에 비해 크다는 단점이 있지만, 이를 편차 제곱으로 바꿔 사용함으로써 보정한다는 장점이 있다.
    2. **recall(재현율)**: 실제 정답인 것들 중 모델이 정답이라 예측한 것들의 비율, 보통 정답으로 예측한 것들 중 실제 정답인 것의 비율인 **precision(정밀도)**과 함께 사용된다. 예를 들면, 암인데 암이 아니다, 사기인데 사기가 아니다 라고 할 경우 치명적일 수 있어 recall의 점수를 높이는 데에 중점을 두고, 욕설 검증이나 스팸과 같은 경우 욕설이나 스팸이 아닌데 마스킹 등의 처리가 될 경우 문제가 될 수 있으므로 precision을 중점적으로 계산한다.

       ![Untitled](%E1%84%86%E1%85%A7%E1%86%AB%E1%84%8C%E1%85%A5%E1%86%B81%20%E1%84%83%E1%85%A1%E1%86%B8%E1%84%87%E1%85%A7%E1%86%AB%20792e284383f94106a8e68a10c54cdc74/recall_precision.png)

    3. **ROC곡선**: FPR에 대한 TPR(재현율과 같이 실제 참인 것 중에 참으로 예측된 비율)의 비율을 그린 그래프
       **AUC**: ROC 곡선 아래의 넓이가 차지하는 비율
       (재현율과 FPR이 겹치는 부분이 작을수록 AUC의 비율이 커지고, 그에 따라 참은 참으로, 거짓은 거짓으로 잘 분류하는 것이기 때문에 모델의 성능을 판단하는 지표로 많이 사용함.)
    4. MAE: 모든 절대 오차의 평균
       선형 함수로 그려지는 오차 함수로 outlier에 강건하다는 장점이 있고 회귀 모델에 자주 사용된다.
    5. f1-score: 정밀도와 재현율의 조화 평균 (특이값의 리스크 회피)
    6. (정답률) accuracy: 모델이 예측한 값 중 정답과 동일한 값의 비율
    7. IoU: intersection of union / CV 분야에서 사용하는 것 중 하나로 모델이 예측한 predicted box와 실제 정답인 ground truth box의 겹친 부분이 정답 box에서 차지하는 비율

    다음엔 메트릭 하나씩 더 찾아오기, 본인이 사용해본 거에 대해 왜 쓰는지 설명할 수 있도록 ([참고](https://velog.io/@lswkim/알고-있는-metric에-대해-설명해주세요.-ex.-RMSE-MAE-recall-precision-))

2.  **정규화를 왜 해야할까요? 정규화의 방법은 무엇이 있나요?**

    1. 모범답안
       정규화는 **개별 피처의 크기를 모두 똑같은 단위로 변경하는 것**을 말한다. 정규화를 하는 이유는 **피처의 스케일이 심하게 차이가 나는 경우 값이 큰 피처가 더 중요하게 여겨질 수 있기 때문**이다. 이를 막기 위해 피처 모두 동일한 스케일로 반영되도록 하는 것이 정규화이다.

    정규화하는 방법으로는 대표적으로 두 가지가 존재한다.
    첫 번째 정규화 방법은 **최소-최대 정규화(min-max normalization)**으로 각 피처의 최소값을 0, 최대값을 1로 두고 변환하는 방법이다. 값을 x로, 최소값을 min, 최대값을 max로 둘 때, 정규화된 값은 (x-min)/(max-min)으로 계산할 수 있다.
    두 번째 정규화 방법으로 **Z-점수 정규화(z-score normalization)**이 있다. 이 방법은 각 피처의 표준편차와 평균으로 값을 정규화시킨다. 정규화된 값은 (x-mean)/std로 계산할 수 있다.

        $$
        \frac{x-min}{max-min}, \frac{x-mean}{std}
        $$

3.  **Local Minima와 Global Minimum에 대해 설명해주세요.**

    1. Gradient descent을 이용해 목적함수의 loss/cost function의 최솟값을 찾는 방법으로 machine learning task를 해결하려고 할 때, 그 최소인 지점이 특정 구간 내에서만 최솟값이면서 gradient가 0인 경우를 **local minima**라 하고, 전체 cost function의 최솟값을 **global minimum**이라 한다. Global minimum에 도달하는 것이 학습의 최종 목표라 할 수 있다. **Local minima**는 최소값이 아닌 다른 극소점으로, Gradient descent와 같은 가중치 업데이트 과정에서 Global minumum을 찾을 때 local minima를 만나면 가중치 업데이트가 중단될 가능성이 있다.
    2. Local Minima로 빠지는 것을 방지하기 위한 다양한 Optimize 기법이 있다. Stocatic Gradient Descent 방법: 데이터의 전체를 활용하지 않고 일부분을 활용하면서 업데이트 하는 방식으로, Local Minima에 빠지더라도 다른 데이터 셋이 사용되었을 때, 빠져나올 수 있다는 장점을 가지고 있다. 기존에는 smooth하게 찾아갔다면, 이는 지그재그 형식으로 Global Minima를 찾아가게 된다.

       그 외에도 방향성을 유지하는 Momentom 기법, 업데이트하는 사이즈를 조정하는 Adagrad 방식, 이 둘을 적절히 합친 Adam 기법이 있다. 주로 프로젝트에서는 Adam을 활용했다.

---

1. **딥러닝과 머신러닝의 차이가 무엇인가요?**
   1. 개념적 차이
      **머신러닝**은 수학적 접근법으로 학습한 데이터에 따라 결정 지표를 만드는 알고리즘으로, 데이터에서 학습하여 예측이나 결정을 내리는 알고리즘들을 포함하는 넓은 분야이다.
      머신러닝의 한 유형으로 볼 수 있는 **딥러닝**은 확률적 접근법으로 학습한 데이터의 특성(feature)을 인지하고 배우지 않은 데이터에 대해 판단하는 성능을 갖춘 인공 신경망이다. 여러 층을 가진 인공신경망을 사용하여 많은 데이터를 다루고 복잡한 계산을 수행함으로써 더 깊고 추상적인 패턴을 학습할 수 있다.
   2. 특징 추출 면에서의 차이
      기존 **머신러닝**에서는 학습하려는 사람이 지정한 알고리즘을 기반으로 특징을 추출하는 반면, 딥러닝은 자동으로 학습하려는 데이터에서 특징을 추출하여 학습한다.
      즉 특징 추출에 사람이 개입하면 머신러닝, 개입하지 않으면 딥러닝이다. 또한 딥러닝은 비선형 활성함수를 통해 머신러닝에 비해 복잡한 문제를 효과적으로 해결할 수 있다.
2. **Cost Function과 Activation Function은 무엇인가요?**
   1. **Cost function(손실 함수)**은 실제 정답값과 모델의 예측 값 사이의 차이를 측정하는 함수로, 모델의 예측이 얼마나 잘못되었는지를 나타내기 때문에 최적화하는 데 중요한 기준이 된다. 이 함수의 연산 값이 작을수록 모델의 성능은 높으며, 모델 학습 중 이 손실을 최소화하기 위해 파라미터 값을 조정한다. 예시로는 MSE, Cross-Entropy 등이 있다.
      **Activation function**은 인공 신경망 내에서 input feature의 총합을 output feature로 변환하는 역할을 하는 함수로, 신경망의 뉴런이 어떻게 활성화될 지를 결정한다. 선형 함수만 사용하는 경우 신경망의 여러 층을 깊게 쌓는 것이 큰 의미가 없게 되는데, 이때 활성화 함수를 사용해 네트워크에 필요한 비선형성을 제공하여 복잡한 문제를 해결할 수 있게 된다. 비선형성을 통해 다층의 layer로 구성된 인공 신경망의 이점을 최대화하는 것이다. 예시로는 sigmoid, ReLU 등이 있다.
3. **Tensorflow, PyTorch 특징과 차이가 뭘까요?**

   1. **Tensorflow**는 Google에서 개발한 라이브러리로, 먼저 모델을 구성하고 나중에 실행하는 정적 계산 그래프 (Define and Run) 방식을 사용하며, 연산의 정의와 실행이 분리되어 있기 때문에 코드가 덜 직관적이라는 단점이 있고
      **Pytorch**는 Facebook에서 개발하였으며, 모델을 구성하는 동시에 실행할 수 있는 동적 계산 그래프 (Define by Run) 방식을 통해 코드를 순차적으로 작성하고 실행하며 모델 구축 및 디버깅에 있어서 더 직관적이라는 장점을 갖고 있다.
   2. **최근 동향**: Pytorch는 주로 학계에서 인기를 얻고 있으며, 연구용 프로젝트나 논문에서 많이 쓰이는 반면, Tensorflow의 경우 구글의 지원과 포괄적인 API를 제공한다는 이점으로 상업적 환경과 상용 어플리케이션에서 많이 쓰인다.

   Tensorflow는 원래 학계와 기업 모두에서 가장 인기 있던 오픈소스 프레임워크였는데, PyTorch가 등장한 이후 커뮤니티의 주도로 다양한 사용 사례에 대한 사용 편의성, 배포 편의성을 개선하며 빠른 속도로 따라잡고 있다고 한다. PyTorch는 자동차 업계에서 활발하게 도입되어 테슬라, 리프트 레벨 (Lyft Lever 5) 등의 자율 운전 시스템 파일럿에 적용되고 있기 때문이다. 게다가 넷플릭스나 왓챠 등 OTT 서비스에서 ‘당신이 좋아할 콘텐츠’ 등 다들 한 번쯤 보셨을 법한 콘텐츠 분류, 추천에 사용되는 기능으로도 활약 중이다.

4. **Data Normalization은 무엇이고 왜 필요한가요?**
   1. [모범 답안](https://github.com/boost-devs/ai-tech-interview/blob/main/answers/3-deep-learning.md#4)
   2. **Normalization**: data feature 간 차이가 많이 날 때, 모든 데이터 포인트의 분포 scale을 0~1 사이의 같은 범위로 변환. MeanMax
      전체 데이터의 분포(scale)를 0~1 사이로 한정하여 표현함으로써 머신러닝에서는 scale이 너무 큰 feature의 영향력을 제한하고 딥러닝에서는 local minima에 빠질 위험을 감소시키며 학습 속도를 향상시키는 효과를 준다. 요약하자면, 이상치를 제거하거나 변수 간의 scale 차이를 조정하고, 모델의 수렴 속도를 향상시켜주는 이점이 있기 때문에 데이터 정규화를 하는 것이 성능 향상에 도움이 된다.
   3. **Regularization**: machine learning에서는 사용하는 parameter의 차수에 따라 주어진 학습 데이터의 경향성을 모두 표현할 수 있는 scability가 향상된다. 그러나 차수가 너무 높은 경우 학습 데이터에 overfitting되어 테스트 데이터에 대해서 성능이 저하될 수 있기 때문에 이를 방지하고자 적절한 수준에서의 성능을 갖는 optimal한 차수를 찾는 것이 중요하다. 따라서 학습 과정에서의 weight 조정에 제약을 걸어 overfitting을 방지하고 일반화된 성능을 높이고자 regularization을 해야 한다.
      학습속도가 개선되고, 노이즈가 작아지므로 오버피팅을 방지할 수 있다. 데이터를 덜 치우치게 해 성능을 높일 수 있고, 모델에 제약을 주어 모델의 복잡성을 낮추고, 이를 통해 오버피팅을 방지할 수 있다. 더불어 Train accuracy는 낮아질 수 있지만, Test accuracy를 높일 수 있다.
   4. **Standardization**(표준화): 데이터의 평균은 0, 편차는 1에 가깝도록 데이터의 분포를 변환.
